{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DenseNet(Pytorch).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMpOgEg9HS+PY54/qzpCZ7g"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"IiL98A6YNEk7"},"source":["import re\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torch.utils.checkpoint as cp\r\n","from collections import OrderedDict\r\n","from .utils import load_state_dict_from_url\r\n","from torch import Tensor\r\n","from typing import Any, List, Tuple\r\n","\r\n","\r\n","__all__ = ['DenseNet', 'densenet121', 'densenet169', 'densenet201', 'densenet161']\r\n","\r\n","model_urls = {\r\n","    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\r\n","    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\r\n","    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\r\n","    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\r\n","}\r\n","\r\n","\r\n","#DenseLayer \r\n","class _DenseLayer(nn.Module):\r\n","    def __init__(\r\n","        self,\r\n","        num_input_features: int,\r\n","        growth_rate: int,\r\n","        bn_size: int,\r\n","        drop_rate: float,\r\n","        memory_efficient: bool = False\r\n","    ) -> None:\r\n","        super(_DenseLayer, self).__init__()\r\n","        self.norm1: nn.BatchNorm2d\r\n","        #Batch Normalization\r\n","        self.add_module('norm1', nn.BatchNorm2d(num_input_features))\r\n","        #ReLU\r\n","        self.relu1: nn.ReLU\r\n","        self.add_module('relu1', nn.ReLU(inplace=True))\r\n","        #Convolution layer\r\n","        self.conv1: nn.Conv2d\r\n","        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\r\n","                                           growth_rate, kernel_size=1, stride=1,\r\n","                                           bias=False))\r\n","        #Batch Normalization\r\n","        self.norm2: nn.BatchNorm2d\r\n","        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate))\r\n","        #ReLU\r\n","        self.relu2: nn.ReLU\r\n","        self.add_module('relu2', nn.ReLU(inplace=True))\r\n","        #Convolution layer\r\n","        self.conv2: nn.Conv2d\r\n","        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\r\n","                                           kernel_size=3, stride=1, padding=1,\r\n","                                           bias=False))\r\n","        self.drop_rate = float(drop_rate)\r\n","        self.memory_efficient = memory_efficient\r\n","\r\n","    def bn_function(self, inputs: List[Tensor]) -> Tensor:\r\n","        concated_features = torch.cat(inputs, 1)\r\n","        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\r\n","        return bottleneck_output\r\n","\r\n","    # todo: rewrite when torchscript supports any\r\n","    def any_requires_grad(self, input: List[Tensor]) -> bool:\r\n","        for tensor in input:\r\n","            if tensor.requires_grad:\r\n","                return True\r\n","        return False\r\n","\r\n","    @torch.jit.unused  # noqa: T484\r\n","    def call_checkpoint_bottleneck(self, input: List[Tensor]) -> Tensor:\r\n","        def closure(*inputs):\r\n","            return self.bn_function(inputs)\r\n","\r\n","        return cp.checkpoint(closure, *input)\r\n","\r\n","    @torch.jit._overload_method  # noqa: F811\r\n","    def forward(self, input: List[Tensor]) -> Tensor:\r\n","        pass\r\n","\r\n","    @torch.jit._overload_method  # noqa: F811\r\n","    def forward(self, input: Tensor) -> Tensor:\r\n","        pass\r\n","\r\n","    # torchscript does not yet support *args, so we overload method\r\n","    # allowing it to take either a List[Tensor] or single Tensor\r\n","    def forward(self, input: Tensor) -> Tensor:  # noqa: F811\r\n","        if isinstance(input, Tensor):\r\n","            prev_features = [input]\r\n","        else:\r\n","            prev_features = input\r\n","\r\n","        if self.memory_efficient and self.any_requires_grad(prev_features):\r\n","            if torch.jit.is_scripting():\r\n","                raise Exception(\"Memory Efficient not supported in JIT\")\r\n","\r\n","            bottleneck_output = self.call_checkpoint_bottleneck(prev_features)\r\n","        else:\r\n","            bottleneck_output = self.bn_function(prev_features)\r\n","\r\n","        #batch normalization -> relu -> convolution layer\r\n","        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\r\n","        if self.drop_rate > 0:\r\n","          #Dropout 적용 \r\n","            new_features = F.dropout(new_features, p=self.drop_rate,\r\n","                                     training=self.training)\r\n","        return new_features\r\n","\r\n","\r\n","class _DenseBlock(nn.ModuleDict):\r\n","    _version = 2\r\n","\r\n","    def __init__(\r\n","        self,\r\n","        num_layers: int,\r\n","        num_input_features: int,\r\n","        bn_size: int,\r\n","        growth_rate: int,\r\n","        drop_rate: float,\r\n","        memory_efficient: bool = False\r\n","    ) -> None:\r\n","        super(_DenseBlock, self).__init__()\r\n","        #dense layer 추가하는 과정 \r\n","        for i in range(num_layers):\r\n","            layer = _DenseLayer(\r\n","                num_input_features + i * growth_rate,\r\n","                growth_rate=growth_rate,\r\n","                bn_size=bn_size,\r\n","                drop_rate=drop_rate,\r\n","                memory_efficient=memory_efficient,\r\n","            )\r\n","\r\n","            self.add_module('denselayer%d' % (i + 1), layer)\r\n","    #desne block의 forward 과정  \r\n","    def forward(self, init_features: Tensor) -> Tensor:\r\n","        features = [init_features]\r\n","        #add_module했던 layer를 통과하며 forward하는 과정 \r\n","        for name, layer in self.items():\r\n","            new_features = layer(features)\r\n","            features.append(new_features)\r\n","        return torch.cat(features, 1)\r\n","\r\n","\r\n","class _Transition(nn.Sequential):\r\n","    def __init__(self, num_input_features: int, num_output_features: int) -> None:\r\n","        super(_Transition, self).__init__()\r\n","        #Batch normalization\r\n","        self.add_module('norm', nn.BatchNorm2d(num_input_features))\r\n","        #ReLU\r\n","        self.add_module('relu', nn.ReLU(inplace=True))\r\n","        #1x1 Conv layer\r\n","        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\r\n","                                          kernel_size=1, stride=1, bias=False))\r\n","        #2x2 Average Pooling\r\n","        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\r\n","\r\n","\r\n","class DenseNet(nn.Module):\r\n","    r\"\"\"Densenet-BC model class, based on\r\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_.\r\n","    Args:\r\n","        growth_rate (int) - how many filters to add each layer (`k` in paper)\r\n","        block_config (list of 4 ints) - how many layers in each pooling block\r\n","        num_init_features (int) - the number of filters to learn in the first convolution layer\r\n","        bn_size (int) - multiplicative factor for number of bottle neck layers\r\n","          (i.e. bn_size * k features in the bottleneck layer)\r\n","        drop_rate (float) - dropout rate after each dense layer\r\n","        num_classes (int) - number of classification classes\r\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\r\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_.\r\n","    \"\"\"\r\n","\r\n","    #growth_rate : 48\r\n","    #block_config : (6, 12, 36, 24)\r\n","    #num_init_features : 96\r\n","    # bn_size: int = 4,\r\n","    # drop_rate: float = 0,\r\n","    # num_classes: int = 1000,\r\n","    # memory_efficient: bool = False\r\n","    def __init__(\r\n","        self,\r\n","        growth_rate: int = 32,\r\n","        block_config: Tuple[int, int, int, int] = (6, 12, 24, 16),\r\n","        num_init_features: int = 64,\r\n","        bn_size: int = 4,\r\n","        drop_rate: float = 0,\r\n","        num_classes: int = 1000,\r\n","        memory_efficient: bool = False\r\n","    ) -> None:\r\n","\r\n","        super(DenseNet, self).__init__()\r\n","\r\n","        # First convolution\r\n","        #첫번째 컨볼루션 \r\n","        self.features = nn.Sequential(OrderedDict([\r\n","            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\r\n","                                padding=3, bias=False)),\r\n","            ('norm0', nn.BatchNorm2d(num_init_features)),\r\n","            ('relu0', nn.ReLU(inplace=True)),\r\n","            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\r\n","        ]))\r\n","\r\n","        # Each denseblock\r\n","        #각 denseblock을 만드는 과정 \r\n","        #densenet161일 경우에는 num_init_features : 96\r\n","        #block_config : (6, 12, 36, 24), 각 denseblock의 denselayer의 개수\r\n","        num_features = num_init_features\r\n","        for i, num_layers in enumerate(block_config):\r\n","            block = _DenseBlock(\r\n","                num_layers=num_layers,\r\n","                num_input_features=num_features,\r\n","                bn_size=bn_size,\r\n","                growth_rate=growth_rate,\r\n","                drop_rate=drop_rate,\r\n","                memory_efficient=memory_efficient\r\n","            )\r\n","            self.features.add_module('denseblock%d' % (i + 1), block) # 만든 denseblock을 features(nn.Sequential)에 추가 \r\n","            #growth_rate : 48\r\n","            #feature map의 channel 개수 정하기\r\n","            num_features = num_features + num_layers * growth_rate\r\n","            if i != len(block_config) - 1:\r\n","                trans = _Transition(num_input_features=num_features,\r\n","                                    num_output_features=num_features // 2)\r\n","                self.features.add_module('transition%d' % (i + 1), trans)\r\n","                num_features = num_features // 2\r\n","\r\n","        # Final batch norm\r\n","        #모든 Denseblock을 다 쌓고 마지막 batch normalization 추가 \r\n","        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\r\n","\r\n","        # Linear layer (분류 층)\r\n","        self.classifier = nn.Linear(num_features, num_classes)\r\n","\r\n","        # Official init from torch repo.\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","            elif isinstance(m, nn.Linear):\r\n","                nn.init.constant_(m.bias, 0)\r\n","\r\n","    def forward(self, x: Tensor) -> Tensor:\r\n","        #이미지를 입력받아서 ~ Denseblock 모두 통과 \r\n","        features = self.features(x)\r\n","        #ReLU 통과 \r\n","        out = F.relu(features, inplace=True)\r\n","        #Global Average Pooling(각 채널마다 채널의 평균값 하나씩)\r\n","        out = F.adaptive_avg_pool2d(out, (1, 1))\r\n","        #Flatten\r\n","        #shape : (batch size, channel, height,width)\r\n","        #dimension 1에 대해서 flatten\r\n","        out = torch.flatten(out, 1)\r\n","        #Linear layer (분류 층)\r\n","        out = self.classifier(out)\r\n","        return out\r\n","\r\n","def _load_state_dict(model: nn.Module, model_url: str, progress: bool) -> None:\r\n","    # '.'s are no longer allowed in module names, but previous _DenseLayer\r\n","    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\r\n","    # They are also in the checkpoints in model_urls. This pattern is used\r\n","    # to find such keys.\r\n","    pattern = re.compile(\r\n","        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\r\n","\r\n","    state_dict = load_state_dict_from_url(model_url, progress=progress)\r\n","    for key in list(state_dict.keys()):\r\n","        res = pattern.match(key)\r\n","        if res:\r\n","            new_key = res.group(1) + res.group(2)\r\n","            state_dict[new_key] = state_dict[key]\r\n","            del state_dict[key]\r\n","    model.load_state_dict(state_dict)\r\n","\r\n","#_densenet('densenet161', 48, (6, 12, 36, 24), 96, pretrained, progress, **kwargs)\r\n","def _densenet(\r\n","    arch: str,\r\n","    growth_rate: int,\r\n","    block_config: Tuple[int, int, int, int],\r\n","    num_init_features: int,\r\n","    pretrained: bool,\r\n","    progress: bool,\r\n","    **kwargs: Any\r\n",") -> DenseNet:\r\n","    #growth_rate : 48\r\n","    #block_config : (6, 12, 36, 24)\r\n","    #num_init_features : 96\r\n","    model = DenseNet(growth_rate, block_config, num_init_features, **kwargs)\r\n","    if pretrained:\r\n","        _load_state_dict(model, model_urls[arch], progress)\r\n","    return model\r\n","\r\n","\r\n","def densenet121(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> DenseNet:\r\n","    r\"\"\"Densenet-121 model from\r\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","        progress (bool): If True, displays a progress bar of the download to stderr\r\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\r\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_.\r\n","    \"\"\"\r\n","    return _densenet('densenet121', 32, (6, 12, 24, 16), 64, pretrained, progress,\r\n","                     **kwargs)\r\n","\r\n","#densenet161 함수 호출\r\n","def densenet161(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> DenseNet:\r\n","    r\"\"\"Densenet-161 model from\r\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","        progress (bool): If True, displays a progress bar of the download to stderr\r\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\r\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_.\r\n","    \"\"\"\r\n","    #_densenet 함수 호출 \r\n","    return _densenet('densenet161', 48, (6, 12, 36, 24), 96, pretrained, progress,\r\n","                     **kwargs)\r\n","\r\n","\r\n","def densenet169(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> DenseNet:\r\n","    r\"\"\"Densenet-169 model from\r\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","        progress (bool): If True, displays a progress bar of the download to stderr\r\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\r\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_.\r\n","    \"\"\"\r\n","    return _densenet('densenet169', 32, (6, 12, 32, 32), 64, pretrained, progress,\r\n","                     **kwargs)\r\n","\r\n","\r\n","def densenet201(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> DenseNet:\r\n","    r\"\"\"Densenet-201 model from\r\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","        progress (bool): If True, displays a progress bar of the download to stderr\r\n","        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\r\n","          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_.\r\n","    \"\"\"\r\n","    return _densenet('densenet201', 32, (6, 12, 48, 32), 64, pretrained, progress,\r\n","                     **kwargs)"],"execution_count":null,"outputs":[]}]}